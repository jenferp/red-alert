{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hands\n",
      "hands2\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp \n",
    "from alert import email_alert\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# define a helper function to detected face\n",
    "def detect_and_predict_blood(frame, bloodNet, check):\n",
    "    # This function takes in an input of the frame, the model, and a \"check\" variable for debugging purposes\n",
    "    # You can remove this check parameter without breaking the code, it was for helping me discover what each variable was easily\n",
    "\n",
    "    detection_list = []\n",
    "    preds = []\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "\n",
    "    detection_list.append(frame)\n",
    "\n",
    "    if check == True:\n",
    "        print(\"detection_list before turning into np.array:\")\n",
    "        #print(type(detection_list))\n",
    "        #print(detection_list)\n",
    "    # Create a numpy array to apply the model, in case that we have multiple things (subject to change depending on if we change the input)\n",
    "    detection_list = np.array(detection_list, dtype=\"float32\")\n",
    "    preds = bloodNet.predict(detection_list, batch_size=32) # DV: bloodNet should be our model to detect blood in a frame\n",
    "        \n",
    "    # Return an array on whether there is blood or no blood in the frame:\n",
    "    # Example: array([[0.00736171 0.99263835]], dtype=\"float32\"). When you access this value, you'll get [[0.00736171 0.99263835]]\n",
    "    return preds\n",
    "\n",
    "# Load the blood detector model from disk\n",
    "bloodNet = load_model('./blood_noblood_classifier.model') # DV: Change the path to our model\n",
    "\n",
    "alert_sent = False\n",
    "blood_counter = 0\n",
    "\n",
    "# Initialize the video stream and allow the camera sensor to warm up\n",
    "#vs = VideoStream(src=0).start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#time.sleep(2.0)\n",
    "\n",
    "print(\"hands\")\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "print(\"hands2\")\n",
    "\n",
    "\n",
    "# Loop over the frames from the video stream\n",
    "while cap.isOpened():\n",
    "    # Grab the frame from the threaded video stream and resize it to have a maximum width of 400 pixels\n",
    "    \n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        # If loading a video, use 'break' instead of 'continue'.\n",
    "        continue\n",
    "        \n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    results = hands.process(frame)\n",
    "\n",
    "    \n",
    "    hand = False\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        hand = True\n",
    "    \n",
    "    if hand == True:\n",
    "        # Run the prediction on blood on the entire frame\n",
    "        preds = detect_and_predict_blood(frame, bloodNet, False)\n",
    "\n",
    "        # Obtain the prediction. preds is an array right now that looks like, for example: [[0.00736171 0.99263835]]\n",
    "        # So we have to create a tuple from the values inside\n",
    "        (noblood, blood) = (preds[0][0], preds[0][1])\n",
    "    else:\n",
    "        (noblood, blood) = (100,0)\n",
    "        \n",
    "    \n",
    "    # Assign a label on whether blood is detected on the screen and assign a color\n",
    "    label = \"Blood\" if blood > noblood else \"no Blood\"\n",
    "    color = (0, 0, 255) if label == \"Blood\" else (0, 255, 0)\n",
    "\n",
    "    # Include the probability in the label\n",
    "    label = \"{}: {:.2f}%\".format(label, max(blood, noblood) * 100)\n",
    "    if alert_sent is True:\n",
    "        label = \"Alert has been sent! Please hold on for help!\"\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "    # Display the label on the frame\n",
    "    cv2.putText(frame, label, (20, 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If blood is detected and an alert has not been sent, send an alert only once after a certain number of frames have passed in a row\n",
    "    if hand == True and blood > noblood and alert_sent is False:\n",
    "        blood_counter = blood_counter + 1\n",
    "        # If the blood counts up for a certain amount of frames, send the alert only one time\n",
    "        # 30 frames is approximately 2 seconds?\n",
    "        if blood_counter > 30:  # This is the number of frames\n",
    "            email_alert(\"red alert test\", \"some one is dyinggggg help\", \"9168376779@messaging.sprintpcs.com\")\n",
    "            alert_sent = True\n",
    "    # Else, reset the counter\n",
    "    elif hand == True and noblood < blood and alert_sent is False:\n",
    "        blood_counter = 0\n",
    "\n",
    "    if key == ord(\"w\"):\n",
    "        alert_sent = False\n",
    "        blood_counter = 0\n",
    "\n",
    "\n",
    "    # If the q is pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        # DV: Check the last frame\n",
    "        # Debug/discovery stuff\n",
    "        # print(\"Q was pressed\")\n",
    "        # preds = detect_and_predict_blood(frame, bloodNet, True)\n",
    "        # print(\"Print preds\")\n",
    "        # print(preds)\n",
    "        # (blood, noblood) = (preds[0][0], preds[0][1])\n",
    "        # print(\"The blood no blood tuple\")\n",
    "        # print((blood, noblood))\n",
    "        # if blood > noblood:\n",
    "        #     print(\"Blood detected\")\n",
    "        # else:\n",
    "        #     print(\"No blood detected\")\n",
    "\n",
    "        break\n",
    "        \n",
    "# Do a bit of cleanup\n",
    "hands.close()\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"Hello World\")\n",
    "time.sleep(2.0)\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from alert import email_alert\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# define a helper function to detected face\n",
    "def detect_and_predict_blood(frame, bloodNet, check):\n",
    "    # This function takes in an input of the frame, the model, and a \"check\" variable for debugging purposes\n",
    "    # You can remove this check parameter without breaking the code, it was for helping me discover what each variable was easily\n",
    "\n",
    "    detection_list = []\n",
    "    preds = []\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "\n",
    "    detection_list.append(frame)\n",
    "\n",
    "    if check == True:\n",
    "        print(\"detection_list before turning into np.array:\")\n",
    "        #print(type(detection_list))\n",
    "        #print(detection_list)\n",
    "    # Create a numpy array to apply the model, in case that we have multiple things (subject to change depending on if we change the input)\n",
    "    detection_list = np.array(detection_list, dtype=\"float32\")\n",
    "    preds = bloodNet.predict(detection_list, batch_size=32) # DV: bloodNet should be our model to detect blood in a frame\n",
    "        \n",
    "    # Return an array on whether there is blood or no blood in the frame:\n",
    "    # Example: array([[0.00736171 0.99263835]], dtype=\"float32\"). When you access this value, you'll get [[0.00736171 0.99263835]]\n",
    "    return preds\n",
    "\n",
    "# Load the blood detector model from disk\n",
    "bloodNet = load_model('./blood_noblood_classifier.model') # DV: Change the path to our model\n",
    "\n",
    "alert_sent = False\n",
    "blood_counter = 0\n",
    "\n",
    "# Initialize the video stream and allow the camera sensor to warm up\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Loop over the frames from the video stream\n",
    "while True:\n",
    "    \n",
    "    # Grab the frame from the threaded video stream and resize it to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "    \n",
    "    image = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "    print(type(image))\n",
    "    results = hands.process(image)\n",
    "    \n",
    "    # Run the prediction on blood on the entire frame\n",
    "    preds = detect_and_predict_blood(frame, bloodNet, False)\n",
    "\n",
    "    # Obtain the prediction. preds is an array right now that looks like, for example: [[0.00736171 0.99263835]]\n",
    "    # So we have to create a tuple from the values inside\n",
    "    (noblood, blood) = (preds[0][0], preds[0][1])\n",
    "    \n",
    "    # Assign a label on whether blood is detected on the screen and assign a color\n",
    "    label = \"Blood\" if blood > noblood else \"No Blood\"\n",
    "    color = (0, 0, 255) if label == \"Blood\" else (0, 255, 0)\n",
    "    \n",
    "    # Include the probability in the label\n",
    "    label = \"{}: {:.2f}%\".format(label, max(blood, noblood) * 100)\n",
    "    if alert_sent is True:\n",
    "        label = \"Alert has been sent! Please hold on for help!\"\n",
    "        color = (0, 0, 255)\n",
    "    \n",
    "    # Display the label on the frame\n",
    "    cv2.putText(frame, label, (20, 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # If blood is detected and an alert has not been sent, send an alert only once after a certain number of frames have passed in a row\n",
    "    if blood > noblood and alert_sent is False:\n",
    "        blood_counter = blood_counter + 1\n",
    "        # If the blood counts up for a certain amount of frames, send the alert only one time\n",
    "        # 30 frames is approximately 2 seconds?\n",
    "        if blood_counter > 30:  # This is the number of frames\n",
    "            email_alert(\"red alert test\", \"some one is dyinggggg help\", \"9168376779@messaging.sprintpcs.com\")\n",
    "            alert_sent = True\n",
    "    # Else, reset the counter\n",
    "    elif noblood < blood and alert_sent is False:\n",
    "        blood_counter = 0\n",
    "    \n",
    "    if key == ord(\"w\"):\n",
    "        alert_sent = False\n",
    "        blood_counter = 0\n",
    "\n",
    "\n",
    "    # If the q is pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        # DV: Check the last frame\n",
    "        # Debug/discovery stuff\n",
    "        # print(\"Q was pressed\")\n",
    "        # preds = detect_and_predict_blood(frame, bloodNet, True)\n",
    "        # print(\"Print preds\")\n",
    "        # print(preds)\n",
    "        # (blood, noblood) = (preds[0][0], preds[0][1])\n",
    "        # print(\"The blood no blood tuple\")\n",
    "        # print((blood, noblood))\n",
    "        # if blood > noblood:\n",
    "        #     print(\"Blood detected\")\n",
    "        # else:\n",
    "        #     print(\"No blood detected\")\n",
    "\n",
    "        break\n",
    "        \n",
    "# Do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from alert import email_alert\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "hands.process?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.3-cp37-cp37m-win_amd64.whl (83.0 MB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (4.5.1.48)\n",
      "Requirement already satisfied: wheel in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (3.15.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (0.11.0)\n",
      "Requirement already satisfied: six in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Collecting numpy==1.19.3\n",
      "  Downloading numpy-1.19.3-cp37-cp37m-win_amd64.whl (13.2 MB)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: numpy, dataclasses, mediapipe\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\users\\\\dylan vu\\\\visual studio code projects\\\\virtualenvs\\\\python37\\\\lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Dylan Vu\\Visual Studio Code Projects\\virtualenvs\\python37\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.8.3-cp37-cp37m-win_amd64.whl (83.0 MB)\n",
      "Requirement already satisfied: six in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (3.15.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: numpy==1.19.3 in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (1.19.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (0.11.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (4.5.1.48)\n",
      "Requirement already satisfied: attrs in c:\\users\\dylan vu\\visual studio code projects\\virtualenvs\\python37\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: dataclasses, mediapipe\n",
      "Successfully installed dataclasses-0.6 mediapipe-0.8.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for -umpy: [Errno 2] No such file or directory: 'c:\\\\users\\\\dylan vu\\\\visual studio code projects\\\\virtualenvs\\\\python37\\\\lib\\\\site-packages\\\\~umpy-1.19.5.dist-info\\\\METADATA'\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Dylan Vu\\Visual Studio Code Projects\\virtualenvs\\python37\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
